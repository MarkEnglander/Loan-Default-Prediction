{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26977f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import useful_functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils import resample\n",
    "import PandasSimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba37e3b",
   "metadata": {},
   "source": [
    "## Classifying the ICL dataset using feature generation and selection\n",
    "The feature generation and selection for this were done in `feature-generation-and-selection-ICL-dataset.ipynb`. In this notebook I use this new dataset for training and testing the classifiers to see whether the feature generation and selection has enabled the classifiers to perform better. I do the following in this notebook:\n",
    "\n",
    "1. Split the dataset into train and test\n",
    "2. Convert the outputs in $[0, 100]$ to outputs in $\\{0, 1\\}$ (to make classification rather than regression possible)\n",
    "3. Use the `median` strategy for data imputation\n",
    "4. Scale the data using `StandardScaler` from sklearn\n",
    "5. Initialize and then train all classifiers using optimised parameters previously found\n",
    "6. Print the confusion matrix for each\n",
    "7. Create, train, and test the voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d588443",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('generated-data/X-train-new2.csv')\n",
    "X_test = pd.read_csv('generated-data/X-test-new2.csv')\n",
    "y_train = pd.read_csv('generated-data/y-train.csv').drop(['Unnamed: 0'], axis=1)\n",
    "y_test = pd.read_csv('generated-data/y-test.csv').drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f09d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = useful_functions.clean_dataset(X_train, delete_missing_data=False).drop(['index', 'Unnamed: 0'], axis=1)\n",
    "X_test = useful_functions.clean_dataset(X_test, delete_missing_data=False).drop(['index', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dced30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_class(y):\n",
    "    class_case = [0 if i < 2.0 else 1 for i in y]\n",
    "    return class_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a77b3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_class = convert_y_to_class(y_train.to_numpy())\n",
    "y_test_class = convert_y_to_class(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd14c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = PandasSimpleImputer.PandasSimpleImputer(strategy='median', missing_values=np.nan)\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d198570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_run(clf):\n",
    "    clf.fit(X_train, y_train_class)\n",
    "    pred_clf = clf.predict(X_test)\n",
    "    print(confusion_matrix(y_test_class, pred_clf))\n",
    "    print(classification_report(y_test_class, pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "823914da",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "GBC = GradientBoostingClassifier(max_depth=4, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 subsample=1, max_features='sqrt', random_state=10, learning_rate=0.15,\n",
    "                                 n_estimators=500)\n",
    "Ada = AdaBoostClassifier(learning_rate=0.5, n_estimators=500)\n",
    "XGBC = XGBClassifier(max_depth=7, min_child_weight=1, gamma=0.1, colsample_bytree=0.8, \n",
    "                                 subsample=0.6, reg_alpha=0, n_estimators=5000, learning_rate=0.01)\n",
    "LGB = LGBMClassifier(subsample_freq=20, n_estimators=400, num_leaves=100, max_depth=20,\n",
    "                                colsample_bytree=0.7, min_split_gain=0.3, reg_alpha=1.3, reg_lambda=1.3,\n",
    "                                subsample=0.8)\n",
    "MLP = MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(100,), learning_rate='adaptive',\n",
    "                                solver='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bf63c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19084   270]\n",
      " [  329  1412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     19354\n",
      "           1       0.84      0.81      0.83      1741\n",
      "\n",
      "    accuracy                           0.97     21095\n",
      "   macro avg       0.91      0.90      0.90     21095\n",
      "weighted avg       0.97      0.97      0.97     21095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_run(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9a1a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19073   281]\n",
      " [  221  1520]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     19354\n",
      "           1       0.84      0.87      0.86      1741\n",
      "\n",
      "    accuracy                           0.98     21095\n",
      "   macro avg       0.92      0.93      0.92     21095\n",
      "weighted avg       0.98      0.98      0.98     21095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_run(GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cedab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19030   324]\n",
      " [  355  1386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     19354\n",
      "           1       0.81      0.80      0.80      1741\n",
      "\n",
      "    accuracy                           0.97     21095\n",
      "   macro avg       0.90      0.89      0.89     21095\n",
      "weighted avg       0.97      0.97      0.97     21095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_run(Ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32173c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:58:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19084   270]\n",
      " [  198  1543]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     19354\n",
      "           1       0.85      0.89      0.87      1741\n",
      "\n",
      "    accuracy                           0.98     21095\n",
      "   macro avg       0.92      0.94      0.93     21095\n",
      "weighted avg       0.98      0.98      0.98     21095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_run(XGBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de82af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19073   281]\n",
      " [  201  1540]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     19354\n",
      "           1       0.85      0.88      0.86      1741\n",
      "\n",
      "    accuracy                           0.98     21095\n",
      "   macro avg       0.92      0.94      0.93     21095\n",
      "weighted avg       0.98      0.98      0.98     21095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_run(LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6d2b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19031   323]\n",
      " [  219  1522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     19354\n",
      "           1       0.82      0.87      0.85      1741\n",
      "\n",
      "    accuracy                           0.97     21095\n",
      "   macro avg       0.91      0.93      0.92     21095\n",
      "weighted avg       0.98      0.97      0.97     21095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_run(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0998195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_votes(ys):\n",
    "    outcomes = []\n",
    "    for i in range(len(ys[0])):\n",
    "        votes_positive = sum([y[i] for y in ys])\n",
    "        results = 1 if votes_positive > len(ys) / 2 else 0\n",
    "        outcomes.append(results)\n",
    "    return outcomes\n",
    "    \n",
    "def get_voting_prediction(X):\n",
    "    RF_pred = RF.predict(X)\n",
    "    GBC_pred = GBC.predict(X)\n",
    "    Ada_pred = Ada.predict(X)\n",
    "    XGBC_pred = XGBC.predict(X)\n",
    "    LGB_pred = LGB.predict(X)\n",
    "    MLP_pred = MLP.predict(X)\n",
    "    return calc_votes([RF_pred, GBC_pred, Ada_pred, XGBC_pred, LGB_pred, MLP_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dfdc76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19095   259]\n",
      " [  244  1497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     19354\n",
      "           1       0.85      0.86      0.86      1741\n",
      "\n",
      "    accuracy                           0.98     21095\n",
      "   macro avg       0.92      0.92      0.92     21095\n",
      "weighted avg       0.98      0.98      0.98     21095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_voting = get_voting_prediction(X_test)\n",
    "print(confusion_matrix(y_test_class, pred_voting))\n",
    "print(classification_report(y_test_class, pred_voting))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
