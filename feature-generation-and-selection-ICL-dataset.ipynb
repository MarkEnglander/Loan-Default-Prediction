{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d973ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as spy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177fb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from useful_code import useful_functions\n",
    "from useful_code import PandasImputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19404fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reliefF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33496f03",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "- Load in the data\n",
    "- Separate into train, validation, and test splits\n",
    "- Use median strategy for imputation of missing data\n",
    "- Re-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d1b332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (135,204,274,417) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/train_v2.csv')\n",
    "data = useful_functions.clean_dataset(data, delete_missing_data=False)\n",
    "data = data.drop(['id', 'index'], axis=1)\n",
    "\n",
    "X = data.drop(['loss'], axis=1)\n",
    "y = data['loss']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "    \n",
    "imp = PandasImputer.PandasImputer(strategy='median', missing_values=np.nan)\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.transform(X_test)\n",
    "X_val = imp.transform(X_val)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f94e3",
   "metadata": {},
   "source": [
    "### The Feature Generation Functions\n",
    "(The following is a paraphrased version of the description in my dissertation followed by the specifics of each function.)\n",
    "\n",
    "The ICL dataset does not have labelled features. The ICL is great because it has many features, but the trade off is that we don't know what they represent. Ordinarily, when looking to generate features, there are at least some hints. For example, if you have the features 'distance' and 'time', you could generate the feature 'speed' using speed = distance / time. In this case we don't have the privilege of making educated guesses.\n",
    "\n",
    "The solution I employ therefore is to generate all possible pairs of features for each operation +, -, \\*. Once generated, I check its pearson correlation with the target feature. If a 3-tuple of two features and an operation is such that this correlation is less than some `sig` then the 4-tuple will be recorded, where the first 3 elements are from the previous 3-tuple and the final is the `op` that should be used.\n",
    "\n",
    "- `get_corr_pairs` requires an `op` (i.e., a 2-function that performs the operation) and returns the list of good 3-tuples (as defined above).\n",
    "- `get_corr_pairs_plus`, `get_corr_pairs_minus` and `get_corr_pairs_mult` use the above function, feeding in `lambda a,b: a+b`, etc., for `op`.\n",
    "- `get_all_corr_pairs` calls all three functions in the above bullet point and concatenates the lists they return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9593df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_pairs(X, y, op, op_name, sig=0.01, suppress_checkpoints=True):\n",
    "    good_pairs = []\n",
    "    no_features = len(X[0])\n",
    "    for i in range(no_features):\n",
    "        if i % 100 == 0 and not suppress_checkpoints:\n",
    "            print('Outer loop up to feature ' + str(i) + '.')\n",
    "        for j in range(i+1, no_features):\n",
    "            corr, _ = spy.pearsonr(op(X[:, i], X[:, j]), y)\n",
    "            if sig < abs(corr):\n",
    "                good_pair = (i, j, corr, op_name)\n",
    "                good_pairs.append(good_pair)\n",
    "    return good_pairs\n",
    "                \n",
    "\n",
    "def get_corr_pairs_plus(X, y, sig=0.01, suppress_checkpoints=True):\n",
    "    plus_pairs = get_corr_pairs(X, y, lambda a,b: a+b, 'plus', sig=sig, suppress_checkpoints=suppress_checkpoints)\n",
    "    return plus_pairs\n",
    "\n",
    "\n",
    "def get_corr_pairs_minus(X, y, sig=0.01, suppress_checkpoints=True):\n",
    "    minus_pairs = get_corr_pairs(X, y, lambda a,b: a-b, 'minus', sig=sig, suppress_checkpoints=suppress_checkpoints)\n",
    "    return minus_pairs\n",
    "    \n",
    "\n",
    "def get_corr_pairs_mult(X, y, sig=0.01, suppress_checkpoints=True):\n",
    "    mult_pairs = get_corr_pairs(X, y, lambda a,b: a*b, 'mult', sig=sig, suppress_checkpoints=suppress_checkpoints)\n",
    "    return mult_pairs\n",
    "\n",
    "\n",
    "def get_all_corr_pairs(X, y, sig=0.01, suppress_checkpoints=True):\n",
    "    all_pairs = get_corr_pairs_plus(X, y, sig, suppress_checkpoints)\n",
    "    if not suppress_checkpoints:\n",
    "        print('Plus pairs done')\n",
    "    all_pairs.extend(get_corr_pairs_minus(X, y, sig, suppress_checkpoints))\n",
    "    if not suppress_checkpoints:\n",
    "        print('Minus pairs done')\n",
    "    all_pairs.extend(get_corr_pairs_mult(X, y, sig, suppress_checkpoints))\n",
    "    if not suppress_checkpoints:\n",
    "        print('Mult pairs done')\n",
    "    return all_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e933aa7c",
   "metadata": {},
   "source": [
    "The following three cells are for use if you don't already have what they generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be7387b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "pairs = get_all_corr_pairs(X_train, y_train, sig=0.013, suppress_checkpoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b55929",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pairs_df = pd.DataFrame.from_records(pairs, columns = ['i_feature', 'j_feature', 'corr_w_target', 'operation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb4ee9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_feature</th>\n",
       "      <th>j_feature</th>\n",
       "      <th>corr_w_target</th>\n",
       "      <th>operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>271</td>\n",
       "      <td>518</td>\n",
       "      <td>-0.155469</td>\n",
       "      <td>minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>517</td>\n",
       "      <td>518</td>\n",
       "      <td>-0.143993</td>\n",
       "      <td>minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>271</td>\n",
       "      <td>517</td>\n",
       "      <td>-0.082747</td>\n",
       "      <td>minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>464</td>\n",
       "      <td>526</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15191</th>\n",
       "      <td>526</td>\n",
       "      <td>545</td>\n",
       "      <td>0.045942</td>\n",
       "      <td>mult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i_feature  j_feature  corr_w_target operation\n",
       "5279         271        518      -0.155469     minus\n",
       "7005         517        518      -0.143993     minus\n",
       "5278         271        517      -0.082747     minus\n",
       "2233         464        526       0.046875      plus\n",
       "15191        526        545       0.045942      mult"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pairs_df.sort_values(by='corr_w_target', key=abs, inplace=True, ascending=False)\n",
    "best_pairs_df.to_csv('best-pairs.csv')\n",
    "best_pairs_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15232021",
   "metadata": {},
   "source": [
    "Or you can just import what the above three generate if you have the file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f188b038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_feature</th>\n",
       "      <th>j_feature</th>\n",
       "      <th>corr_w_target</th>\n",
       "      <th>operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271</td>\n",
       "      <td>518</td>\n",
       "      <td>-0.155469</td>\n",
       "      <td>minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>517</td>\n",
       "      <td>518</td>\n",
       "      <td>-0.143993</td>\n",
       "      <td>minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271</td>\n",
       "      <td>517</td>\n",
       "      <td>-0.082747</td>\n",
       "      <td>minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464</td>\n",
       "      <td>526</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>526</td>\n",
       "      <td>545</td>\n",
       "      <td>0.045942</td>\n",
       "      <td>mult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_feature  j_feature  corr_w_target operation\n",
       "0        271        518      -0.155469     minus\n",
       "1        517        518      -0.143993     minus\n",
       "2        271        517      -0.082747     minus\n",
       "3        464        526       0.046875      plus\n",
       "4        526        545       0.045942      mult"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pairs_df = pd.read_csv('best-pairs.csv')\n",
    "best_pairs_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "best_pairs_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3384cc",
   "metadata": {},
   "source": [
    "### Generating the highly correlated features\n",
    "Given some `X` matrix and a DataFrame `best_pair_df` which has the stated 4-tuples, `gen_new_dataset` returns `X` with the top `n` additional features generated and added to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e363c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new_dataset(X, best_pairs_df, n=100):\n",
    "    X_new = pd.DataFrame(X.copy())\n",
    "    i = 'i_feature'\n",
    "    j = 'j_feature'\n",
    "    for index, row in best_pairs_df.iterrows():\n",
    "        if index < 100:\n",
    "            if row['operation'] == 'minus':\n",
    "                X_new[str(row[i]) + '-' + str(row[j])] = X_new.iloc[:, row[i]] - X_new.iloc[:, row[j]]\n",
    "            if row['operation'] == 'plus':\n",
    "                X_new[str(row[i]) + '+' + str(row[j])] = X_new.iloc[:, row[i]] + X_new.iloc[:, row[j]]\n",
    "            if row['operation'] == 'mult':\n",
    "                X_new[str(row[i]) + '*' + str(row[j])] = X_new.iloc[:, row[i]] * X_new.iloc[:, row[j]]\n",
    "    return X_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c906edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = gen_new_dataset(X_train, best_pairs_df, 100)\n",
    "X_val_new = gen_new_dataset(X_val, best_pairs_df, 100)\n",
    "X_test_new = gen_new_dataset(X_test, best_pairs_df, 100)\n",
    "X_new = np.concatenate([X_train_new, X_val_new, X_test_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d578f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_new).to_csv('generated-data/X-train-new.csv')\n",
    "pd.DataFrame(X_val_new).to_csv('generated-data/X-val-new.csv')\n",
    "pd.DataFrame(X_test_new).to_csv('generated-data/X-test-new.csv')\n",
    "pd.DataFrame(X_new).to_csv('generated-data/X-new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecd69c",
   "metadata": {},
   "source": [
    "### Feature Selection - Relief\n",
    "I use an implementation of relief which can be found at https://github.com/gitter-badger/ReliefF/blob/master/ReliefF/ReliefF.py\n",
    "This is *not* my implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2b71321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relief = reliefF.ReliefF(n_neighbors=70, n_features_to_keep=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fb5280f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relief.fit(X_train_new, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee2c0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relief.top_features).to_csv('relief-top-features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad8d41",
   "metadata": {},
   "source": [
    "### Feature Selection - Using a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd845e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_class(y):\n",
    "    class_case = [0 if i < 2.0 else 1 for i in y]\n",
    "    return class_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faa7ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_class = convert_y_to_class(y_train)\n",
    "y_val_class = convert_y_to_class(y_val)\n",
    "y_test_class = convert_y_to_class(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7660b6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train_new, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f05182b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19185,   151],\n",
       "       [  815,   943]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_val_new)\n",
    "confusion_matrix(y_val_class, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb9f07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a37c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importances = pd.DataFrame(std, columns=['std'])\n",
    "df_importances['feature'] = df_importances.index\n",
    "best_features = np.array(df_importances.sort_values(by='std', ascending=False)['feature'].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e85648f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([763, 765, 764,   1,  22, 269, 374, 248, 329, 375, 637, 334, 268,\n",
       "       411, 647, 200, 750, 289,  70, 331, 332, 646, 505, 218, 420, 275,\n",
       "       208, 519, 648, 249, 321, 582, 373, 416, 769, 335, 827, 401, 271,\n",
       "       336, 831, 614, 330, 258, 219, 410, 399, 779, 209, 782], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "297acd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new2 = X_train_new[:, best_features]\n",
    "X_test_new2 = X_test_new[:, best_features]\n",
    "X_val_new2 = X_val_new[:, best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c915d6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=100)\n",
    "rf2.fit(X_train_new2, y_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8fdf8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     19336\n",
      "           1       0.83      0.81      0.82      1758\n",
      "\n",
      "    accuracy                           0.97     21094\n",
      "   macro avg       0.91      0.90      0.90     21094\n",
      "weighted avg       0.97      0.97      0.97     21094\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19051,   285],\n",
       "       [  333,  1425]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = rf2.predict(X_val_new2)\n",
    "print(classification_report(y_val_class, y_pred2))\n",
    "confusion_matrix(y_val_class, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "171a0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new2 = np.concatenate([X_train_new2, X_val_new2, X_test_new2])\n",
    "pd.DataFrame(X_train_new2).to_csv('generated-data/X-train-new2.csv')\n",
    "pd.DataFrame(X_val_new2).to_csv('generated-data/X-val-new2.csv')\n",
    "pd.DataFrame(X_test_new2).to_csv('generated-data/X-test-new2.csv')\n",
    "pd.DataFrame(X_new2).to_csv('generated-data/X-new2.csv')\n",
    "pd.DataFrame(np.concatenate([y_train, y_val, y_test])).to_csv('generated-data/y-in-order-for-new2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceaa76ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).to_csv('generated-data/y-train.csv')\n",
    "pd.DataFrame(y_val).to_csv('generated-data/y-val.csv')\n",
    "pd.DataFrame(y_test).to_csv('generated-data/y-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad62ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
